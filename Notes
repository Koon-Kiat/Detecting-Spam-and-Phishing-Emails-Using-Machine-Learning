class email_to_clean_text(BaseEstimator, TransformerMixin):
    def __init__(self):
        pass

    def fit(self, X, y=None):
        return self

    def transform(self, X):
        text_list = []
        for mail in X:
            # Converts raw email string into email message object
            b = email.message_from_string(mail)
            body = ""

            if b.is_multipart():
                for part in b.walk():
                    ctype = part.get_content_type()
                    cdispo = str(part.get('Content-Disposition'))

                    # Skip any text/plain (txt) attachments
                    if ctype == 'text/plain' and 'attachment' not in cdispo:
                        body = part.get_payload(
                            decode=True)  # get body of email
                        break
            # Not multipart - i.e. plain text, no attachments
            else:
                # Get body of email
                body = b.get_payload(decode=True)

            # Get text from body (HTML/text)
            soup = BeautifulSoup(body, "html.parser")
            # Convert text to lowercase
            text = soup.get_text().lower()
            # Remove links
            text = re.sub(
                r'(https|http)?:\/\/(\w|\.|\/|\?|\=|\&|\%)*\b', '', text, flags=re.MULTILINE)
            # Remove email address
            text = re.sub(
                r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '', text, flags=re.MULTILINE)
            # Remove punctuation
            text = text.translate(str.maketrans(
                '', '', string.punctuation))  # remove punctuation
            # Remove digits
            text = ''.join([i for i in text if not i.isdigit()])
            # Loads a list of stopwords
            stop_words = stopwords.words('english')
            # Remove stop words
            words_list = [w for w in text.split() if w not in stop_words]
            # Lemmatize (Reduce word to base form, while retaining context)
            words_list = [lemmatizer.lemmatize(w) for w in words_list]
            # Stemming (Reduce word to base from by removing suffixes and prefixes)
            words_list = [stemmer.stem(w) for w in words_list]  # Stemming
            text_list.append(' '.join(words_list))
        return text_list
    
    # Extract cleaned text into csv file
    def save_to_csv_cleaned(self, text_list, filename):
        # Converts the text into a dataframe
        df = pd.DataFrame(text_list, columns=['cleaned_text'])
        df.to_csv(filename, index=False)
        print(f"Data saved to {filename}")

Following the previous example i want you to clean 